{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da base de dados `Beta` utilizando algoritmos de ML\n",
    "\n",
    "Neste notebook será analisado o `Beta dataset` utilizando algoritmos de ML para realizar a (1) extração de características, (2) seleção de características e (3) classificação dos dados\n",
    "\n",
    "### Pontos importantes do dataset\n",
    "\n",
    "- Frequências estimuladas (total de 40, com a diferença de 0.2 Hz uma da outra): 8.0, 8.2, ..., 15.6, 15.8;\n",
    "- Taxa de amostragem: 250 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisar os \"momentos\" em que ocorrem evocação do sinal SSVEP\n",
    "\n",
    "1. Criar o objeto `MNE` a partir dos dados dados do participante;\n",
    "2. Aplicar no objeto `MNE` o filtro passa-faixa nos valores de 6 - 18 Hz;\n",
    "3. Criar cópias do objeto `MNE` com fatias de tempo menores para analisar momentos que ocorrem estimulos ou não (verificar artigo);\n",
    "    a) 0.0 - 0.5 segundos e 2.5 - 3.0 segundos ocorre apenas ruído;\n",
    "    b) 0.5 - 2.5 segundos ocorre sinal SSVEP (com ruídos)\n",
    "4. Com os sinais separados em objetos `MNE`, aplicar a `FFT`, para que seja possível plotar gráficos que contenham (ou não) as informações.\n",
    "    - Os dados devem ser plotados no domínio da frequência (após a transformada de Fourier). O FFT pode ser realizado pela biblioteca `scipy.fft`.\n",
    "    - Deve ser observado que as janelas (a) com ruído não aparecerão de fato o sinal SSVEP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração de características\n",
    "\n",
    "Uma característica importante de acordo com o artigo base do dataset `BETA` é o *signal-to-noise ratio* (SNR).\n",
    "São dois tipos de características SNR que podem ser implementadas: SNR de banda estreita (`narrow-SNR`) e SNR de banda larga (`wide-band SNR`).\n",
    "\n",
    "Uma boa prática, é considerar o ruído das medidas de `SNR`, uma vez que os dados `SSVEP` não estão estimulados durante os períodos de 0 a 0,5 segundos e de 2,5 a 3 segundos. O ruído pode afetar a precisão das medidas de `SNR` e, portanto, é aconselhável levar isso em consideração.\n",
    "\n",
    "Vamos realizar todos esses cálculos com dados fictícios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mne\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from copy import deepcopy\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 750, 160) (160,)\n"
     ]
    }
   ],
   "source": [
    "data = loadmat(f\"../../dataset/beta/S12.mat\")['data'][0][0]\n",
    "eeg_data = data[0]\n",
    "eeg = eeg_data.reshape(eeg_data.shape[0], eeg_data.shape[1], eeg_data.shape[2] * eeg_data.shape[3])\n",
    "labels = np.array(list(data[1]['freqs'][0][0].flatten()) * 4)\n",
    "print(eeg.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 750)\n"
     ]
    }
   ],
   "source": [
    "data_correct = eeg.swapaxes(0, 2)\n",
    "data_correct = data_correct.swapaxes(1, 2)\n",
    "print(data_correct.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos estimar o ruído de fundo, para calcular posteriormente o `narrow SNR` e o `wide-band SNR`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 750)\n",
      "(160,)\n",
      "28376881.989714384\n"
     ]
    }
   ],
   "source": [
    "dataset = deepcopy(data_correct)\n",
    "print(dataset.shape)\n",
    "\n",
    "# intervalos de tempo sem estímulo (0 a 0,5 segundos e 2,5 a 3 segundos)\n",
    "base_start = 0\n",
    "base_end = 125\n",
    "rest_start = 625\n",
    "rest_end = 750\n",
    "\n",
    "# Estimando o ruído de fundo\n",
    "estimated_background_noise = []\n",
    "\n",
    "for trial in dataset: #para cada sinal   \n",
    "    noise_power = [] # armazena uma lista com as médias de potência para cada canal\n",
    "\n",
    "    for electrode in trial:\n",
    "        psd = np.abs(np.fft.fft(electrode)) ** 2\n",
    "\n",
    "        # média da potência nos intervalos de tempo sem estímulo\n",
    "        base_power = np.mean(psd[base_start:base_end])\n",
    "        rest_power = np.mean(psd[rest_start:rest_end])\n",
    "        mean_noise_power = (base_power + rest_power) / 2\n",
    "\n",
    "        noise_power.append(mean_noise_power)\n",
    "\n",
    "    #média das médias de potência de todos os canais para estimar o ruído de fundo\n",
    "    estimated_background_noise.append(np.mean(noise_power))\n",
    "# end\n",
    "\n",
    "\n",
    "background_noise = np.array(estimated_background_noise)\n",
    "print(background_noise.shape)\n",
    "print(np.mean(background_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de calcular os SNRs, precisamos obter as amplitudes alvo por meio dos dados EEG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 64, 40)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "sr = 250\n",
    "\n",
    "# frequências alvo\n",
    "target_frequencies = np.arange(8, 16, 0.2)\n",
    "# lista para armazenar as amplitudes nas frequências alvo\n",
    "target_amplitudes = []\n",
    "\n",
    "for x in range(dataset.shape[0]):\n",
    "    samples = []\n",
    "    \n",
    "    for channel_data in dataset[x, :, :]:\n",
    "        fft_result = np.fft.fft(channel_data)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "        frequencies = np.fft.fftfreq(len(fft_result), 1 / sr)\n",
    "        target_amplitudes_trial = []\n",
    "        for target_frequency in target_frequencies:\n",
    "        # encontrando o índice da frequência alvo no espectro de frequência\n",
    "            index = np.argmin(np.abs(frequencies - target_frequency))\n",
    "            # amplitude na frequência alvo\n",
    "            amplitude = np.sqrt(psd[index])\n",
    "            target_amplitudes_trial.append(amplitude)\n",
    "        samples.append(target_amplitudes_trial)\n",
    "    target_amplitudes.append(samples)\n",
    "target_amplitudes = np.array(target_amplitudes)\n",
    "target_amplitudes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular o SNR de \"banda estreita\". Pode ser observado pela seguinte equação:\n",
    "\n",
    "$SNR_{banda\\ estreita} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{média das amplitudes nas frequências vizinhas}}\\right)$\n",
    "\n",
    "Já o SNR de banda larga é definido da seguinte forma:\n",
    "\n",
    "$SNR_{banda\\ larga} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{energia total do espectro de amplitude}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def narrow_band_SNR(target_amplitudes, estimated_background_noise):\n",
    "  target_amplitudes_adjusted = np.abs(target_amplitudes - estimated_background_noise)\n",
    "  return 10 * np.log10(target_amplitudes_adjusted / estimated_background_noise)\n",
    "\n",
    "def wide_band_SNR(target_amplitudes, estimated_background_noise):\n",
    "  target_amplitudes_adjusted = np.abs(target_amplitudes - estimated_background_noise)\n",
    "  total_power = np.sum(target_amplitudes_adjusted)\n",
    "  return 10 * np.log10(target_amplitudes_adjusted / total_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remoção manual de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 80)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = labels\n",
    "\n",
    "for i, trial in enumerate(dataset):\n",
    "  X.append([\n",
    "    narrow_band_SNR(target_amplitudes[i], background_noise[i]),\n",
    "    wide_band_SNR(target_amplitudes[i], background_noise[i])\n",
    "  ])\n",
    "  \n",
    "X = np.array(X)\n",
    "X = X.swapaxes(1, 2)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2]*X.shape[3])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gregu\\Projetos\\SSVEP\\r_padrao\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Remoção\n",
    "# opções: ['PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'POZ', 'O1', 'OZ', 'O2'] -> [47, 53, 54, 55, 56, 57, 60, 61, 62]\n",
    "Xmanual = deepcopy(X)\n",
    "Xmanual = Xmanual[:,[47, 53, 54, 55, 56, 57, 60, 61, 62],:]\n",
    "Xmanual = Xmanual.reshape(Xmanual.shape[0], Xmanual.shape[1]*Xmanual.shape[2])\n",
    "\n",
    "#preparing\n",
    "Xmanual = StandardScaler().fit_transform(Xmanual)\n",
    "ym = LabelEncoder().fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xmanual, ym, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remoção automática de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 80)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = labels\n",
    "\n",
    "for i, trial in enumerate(dataset):\n",
    "  X.append([\n",
    "    narrow_band_SNR(target_amplitudes[i], background_noise[i]),\n",
    "    wide_band_SNR(target_amplitudes[i], background_noise[i])\n",
    "  ])\n",
    "  \n",
    "X = np.array(X)\n",
    "X = X.swapaxes(1, 2)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2]*X.shape[3])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 5120) (160,)\n",
      "(160, 183)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gregu\\Projetos\\SSVEP\\SSVEP\\src\\Beta\\beta_ml.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gregu/Projetos/SSVEP/SSVEP/src/Beta/beta_ml.ipynb#Y110sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_final, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gregu/Projetos/SSVEP/SSVEP/src/Beta/beta_ml.ipynb#Y110sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m clf \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m, C\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, probability\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gregu/Projetos/SSVEP/SSVEP/src/Beta/beta_ml.ipynb#Y110sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gregu/Projetos/SSVEP/SSVEP/src/Beta/beta_ml.ipynb#Y110sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gregu/Projetos/SSVEP/SSVEP/src/Beta/beta_ml.ipynb#Y110sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\gregu\\Projetos\\SSVEP\\r_padrao\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gregu\\Projetos\\SSVEP\\r_padrao\\Lib\\site-packages\\sklearn\\svm\\_base.py:199\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    204\u001b[0m solver_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n",
      "File \u001b[1;32mc:\\Users\\gregu\\Projetos\\SSVEP\\r_padrao\\Lib\\site-packages\\sklearn\\svm\\_base.py:743\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_targets\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m    742\u001b[0m     y_ \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 743\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    744\u001b[0m     \u001b[39mcls\u001b[39m, y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight_ \u001b[39m=\u001b[39m compute_class_weight(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, classes\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, y\u001b[39m=\u001b[39my_)\n",
      "File \u001b[1;32mc:\\Users\\gregu\\Projetos\\SSVEP\\r_padrao\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:215\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    207\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m ]:\n\u001b[1;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    216\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "# preparing\n",
    "Xauto = deepcopy(X)\n",
    "Xauto = Xauto.reshape(Xauto.shape[0], Xauto.shape[1]*Xauto.shape[2])\n",
    "Xauto = StandardScaler().fit_transform(Xauto)\n",
    "ya = LabelEncoder().fit_transform(y)\n",
    "print(Xauto.shape, ya.shape)\n",
    "\n",
    "#rfe\n",
    "rfe = RFECV(svm.SVC(kernel=\"linear\"), step=0.0001, min_features_to_select=1, cv=3)\n",
    "X_final = rfe.fit_transform(Xauto, ya)\n",
    "print(X_final.shape)\n",
    "\n",
    "#svm\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, ya, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao final desta etapa, será obtido um vetor de características. Estas podem ser:\n",
    "- `narrow SNR` (brigatória);\n",
    "- `wide-band SNR` (brigatória);\n",
    "- Maior valor espectral (FFT);\n",
    "- Média dos valores espectrais (FFT).\n",
    "\n",
    "Dimensionalidade dos dados será explicada da seguinte forma:\n",
    "\n",
    "`40, 4, 64, 750` -> 40 targets, 4 trials, 64 canais e 750 valores\n",
    "`160, 64 (SNR) + 64 (média) + 64 (maior) ...`\n",
    "Resultando em `160, 192`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de características e classificação\n",
    "\n",
    "Como existem diversos eletrodos (canais) que não obtém sinal SSVEP, podemos extrair as caracteríscas que não contribuem para a classificação dos dados.\n",
    "\n",
    "Podemos utilizar o método `RFE` (*Recursive Feature Elimination*) aplicado por meio de `sklearn.feature_selection.RFE`, aprimorando o parâmetro `n_features_to_select` até obter o melhor resultado de classificação.\n",
    "\n",
    "Para a classificação propriamente dita, é considerado o uso do método `SVM`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
