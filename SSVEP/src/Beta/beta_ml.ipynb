{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da base de dados `Beta` utilizando algoritmos de ML\n",
    "\n",
    "Neste notebook será analisado o `Beta dataset` utilizando algoritmos de ML para realizar a (1) extração de características, (2) seleção de características e (3) classificação dos dados\n",
    "\n",
    "### Pontos importantes do dataset\n",
    "\n",
    "- Frequências estimuladas (total de 40, com a diferença de 0.2 Hz uma da outra): 8.0, 8.2, ..., 15.6, 15.8;\n",
    "- Taxa de amostragem: 250 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisar os \"momentos\" em que ocorrem evocação do sinal SSVEP\n",
    "\n",
    "1. Criar o objeto `MNE` a partir dos dados dados do participante;\n",
    "2. Aplicar no objeto `MNE` o filtro passa-faixa nos valores de 6 - 18 Hz;\n",
    "3. Criar cópias do objeto `MNE` com fatias de tempo menores para analisar momentos que ocorrem estimulos ou não (verificar artigo);\n",
    "    a) 0.0 - 0.5 segundos e 2.5 - 3.0 segundos ocorre apenas ruído;\n",
    "    b) 0.5 - 2.5 segundos ocorre sinal SSVEP (com ruídos)\n",
    "4. Com os sinais separados em objetos `MNE`, aplicar a `FFT`, para que seja possível plotar gráficos que contenham (ou não) as informações.\n",
    "    - Os dados devem ser plotados no domínio da frequência (após a transformada de Fourier). O FFT pode ser realizado pela biblioteca `scipy.fft`.\n",
    "    - Deve ser observado que as janelas (a) com ruído não aparecerão de fato o sinal SSVEP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração de características\n",
    "\n",
    "Uma característica importante de acordo com o artigo base do dataset `BETA` é o *signal-to-noise ratio* (SNR).\n",
    "São dois tipos de características SNR que podem ser implementadas: SNR de banda estreita (`narrow-SNR`) e SNR de banda larga (`wide-band SNR`).\n",
    "\n",
    "Uma boa prática, é considerar o ruído das medidas de `SNR`, uma vez que os dados `SSVEP` não estão estimulados durante os períodos de 0 a 0,5 segundos e de 2,5 a 3 segundos. O ruído pode afetar a precisão das medidas de `SNR` e, portanto, é aconselhável levar isso em consideração.\n",
    "\n",
    "Vamos realizar todos esses cálculos com dados fictícios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mne\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from copy import deepcopy\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from joblib import Parallel, delayed\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 750, 160) (160,)\n"
     ]
    }
   ],
   "source": [
    "data = loadmat(f\"../../dataset/beta/S12.mat\")['data'][0][0]\n",
    "eeg_data = data[0]\n",
    "eeg = eeg_data.reshape(eeg_data.shape[0], eeg_data.shape[1], eeg_data.shape[2] * eeg_data.shape[3])\n",
    "labels = np.array(list(data[1]['freqs'][0][0].flatten()) * 4)\n",
    "print(eeg.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.6,  8.8,  9. ,  9.2,  9.4,  9.6,  9.8, 10. , 10.2, 10.4, 10.6,\n",
       "       10.8, 11. , 11.2, 11.4, 11.6, 11.8, 12. , 12.2, 12.4, 12.6, 12.8,\n",
       "       13. , 13.2, 13.4, 13.6, 13.8, 14. , 14.2, 14.4, 14.6, 14.8, 15. ,\n",
       "       15.2, 15.4, 15.6, 15.8,  8. ,  8.2,  8.4,  8.6,  8.8,  9. ,  9.2,\n",
       "        9.4,  9.6,  9.8, 10. , 10.2, 10.4, 10.6, 10.8, 11. , 11.2, 11.4,\n",
       "       11.6, 11.8, 12. , 12.2, 12.4, 12.6, 12.8, 13. , 13.2, 13.4, 13.6,\n",
       "       13.8, 14. , 14.2, 14.4, 14.6, 14.8, 15. , 15.2, 15.4, 15.6, 15.8,\n",
       "        8. ,  8.2,  8.4,  8.6,  8.8,  9. ,  9.2,  9.4,  9.6,  9.8, 10. ,\n",
       "       10.2, 10.4, 10.6, 10.8, 11. , 11.2, 11.4, 11.6, 11.8, 12. , 12.2,\n",
       "       12.4, 12.6, 12.8, 13. , 13.2, 13.4, 13.6, 13.8, 14. , 14.2, 14.4,\n",
       "       14.6, 14.8, 15. , 15.2, 15.4, 15.6, 15.8,  8. ,  8.2,  8.4,  8.6,\n",
       "        8.8,  9. ,  9.2,  9.4,  9.6,  9.8, 10. , 10.2, 10.4, 10.6, 10.8,\n",
       "       11. , 11.2, 11.4, 11.6, 11.8, 12. , 12.2, 12.4, 12.6, 12.8, 13. ,\n",
       "       13.2, 13.4, 13.6, 13.8, 14. , 14.2, 14.4, 14.6, 14.8, 15. , 15.2,\n",
       "       15.4, 15.6, 15.8,  8. ,  8.2,  8.4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 750)\n"
     ]
    }
   ],
   "source": [
    "data_correct = eeg.swapaxes(0, 2)\n",
    "data_correct = data_correct.swapaxes(1, 2)\n",
    "print(data_correct.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos estimar o ruído de fundo, para calcular posteriormente o `narrow SNR` e o `wide-band SNR`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "dataset = deepcopy(data_correct)\n",
    "print(dataset.shape)\n",
    "\n",
    "# intervalos de tempo sem estímulo (0 a 0,5 segundos e 2,5 a 3 segundos)\n",
    "base_start = 0\n",
    "base_end = 125\n",
    "rest_start = 625\n",
    "rest_end = 750\n",
    "\n",
    "# Estimando o ruído de fundo\n",
    "estimated_background_noise = []\n",
    "\n",
    "for trial in dataset: #para cada sinal   \n",
    "    noise_power = [] # armazena uma lista com as médias de potência para cada canal\n",
    "\n",
    "    for electrode in trial:\n",
    "        fft_result = np.fft.fft(electrode)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "\n",
    "        # média da potência nos intervalos de tempo sem estímulo\n",
    "        base_power = np.mean(psd[base_start:base_end])\n",
    "        rest_power = np.mean(psd[rest_start:rest_end])\n",
    "        mean_noise_power = (base_power + rest_power) / 2\n",
    "\n",
    "        noise_power.append(mean_noise_power)\n",
    "\n",
    "    #média das médias de potência de todos os canais para estimar o ruído de fundo\n",
    "    estimated_background_noise.append(np.mean(noise_power))\n",
    "# end\n",
    "\n",
    "\n",
    "background_noise = np.array(estimated_background_noise)\n",
    "print(background_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30498333.90833097, 30516368.3296105 , 30112336.14273042,\n",
       "       30008834.01658553, 29470583.39909198, 29617385.36492788,\n",
       "       29266264.52336321, 30395129.63840988, 30077072.69304765,\n",
       "       29586487.54202674, 30501150.14739981, 30502673.76599781,\n",
       "       30796684.32594546, 29844888.50359821, 29732780.51121324,\n",
       "       29132578.40147852, 30214754.94051994, 29418508.82781163,\n",
       "       29997038.5113678 , 30164577.97419317, 30503213.60638619,\n",
       "       29367576.06274265, 30460303.12397649, 29631067.32819466,\n",
       "       29599279.92893031, 30769441.41872721, 30594147.50366092,\n",
       "       29614562.46225711, 30405863.10376182, 29623792.94142328,\n",
       "       30493453.68967614, 30493192.57855798, 30111584.35052999,\n",
       "       29891839.91923435, 30073118.50152112, 29542519.47640851,\n",
       "       29439322.06121934, 28859577.78896644, 29626998.07968577,\n",
       "       29773363.13217536, 29772367.82444989, 30335532.73310211,\n",
       "       29849866.77166615, 29730717.14306886, 29445580.06857408,\n",
       "       30023458.50968016, 30027607.10144359, 30572092.00825093,\n",
       "       30429553.18600075, 30347559.82422637, 30655369.25028152,\n",
       "       29252183.75917233, 30546822.01402995, 30725638.83484649,\n",
       "       30317752.75408107, 30434391.56817146, 28591762.00711443,\n",
       "       30037254.32090773, 30879066.55239566, 30713869.26630647,\n",
       "       30745623.46776272, 30370736.63707952, 30169094.84962565,\n",
       "       30101594.91559785, 29622852.29984047, 29793857.5996785 ,\n",
       "       30146515.30799026, 30030070.96411506, 29731357.98327328,\n",
       "       30451100.37559672, 30544195.00562012, 30783500.5476819 ,\n",
       "       30664913.89193535, 30775535.60262127, 30071212.29636373,\n",
       "       29880711.03488638, 29771140.22594997, 30540747.24920751,\n",
       "       29557738.44424425, 30343638.26100193, 27079151.71637294,\n",
       "       27942742.35903475, 27442060.8153525 , 24880748.30668012,\n",
       "       22454395.15624649, 26381735.76887379, 29901807.63325106,\n",
       "       27323350.57058729, 29231038.82995157, 25238826.6654305 ,\n",
       "       30037666.29822179, 27283533.7245247 , 29711015.04099761,\n",
       "       28885866.61594802, 27447816.60796415, 29975029.65202343,\n",
       "       22312212.79372776, 28556793.19609774, 28861874.96593404,\n",
       "       29847601.52784545, 28104546.11394903, 28233242.82033956,\n",
       "       21807275.03639967, 26272299.92221465, 29170852.11388335,\n",
       "       29959150.62414896, 30181923.9497281 , 28819202.87279934,\n",
       "       29067571.27168754, 29670614.64007705, 25930249.46465774,\n",
       "       30694321.37437369, 26132002.18494629, 29897173.61443035,\n",
       "       28402476.65007762, 29494693.25654769, 29146034.28184132,\n",
       "       30664937.51180035, 28985448.57887806, 30548974.80433487,\n",
       "       22258251.3061849 , 22966839.02508772, 24146664.78269206,\n",
       "       21607990.43805878, 23056839.59266724, 22458297.22927693,\n",
       "       25152480.53714576, 23205931.2421658 , 22470056.13860414,\n",
       "       28199229.5113634 , 28105378.14538584, 30852916.66489727,\n",
       "       25524449.5786377 , 28654036.3787793 , 29766969.55192288,\n",
       "       29879721.25016519, 21979210.47142886, 27416611.95396699,\n",
       "       23070327.9867468 , 25049139.36964031, 25256735.71468613,\n",
       "       28777825.86791027, 27097473.03064943, 25995015.27597015,\n",
       "       30719799.04787958, 24663059.34304492, 26910616.12257868,\n",
       "       22560758.84074749, 23628082.6898354 , 20901692.20997261,\n",
       "       22902137.63054882, 26782825.30259475, 24483708.9012587 ,\n",
       "       23205686.96295092, 23224191.36513621, 29001893.15132529,\n",
       "       21467254.26918449, 23619200.21841206, 25485376.29628154,\n",
       "       30304954.64280709])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de calcular os SNRs, precisamos obter as amplitudes alvo por meio dos dados EEG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 64, 40)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "sr = 250\n",
    "\n",
    "# frequências alvo\n",
    "target_frequencies = np.arange(8, 16, 0.2)\n",
    "# lista para armazenar as amplitudes nas frequências alvo\n",
    "target_amplitudes = []\n",
    "\n",
    "for x in range(dataset.shape[0]):\n",
    "    samples = []\n",
    "    \n",
    "    for channel_data in dataset[x, :, :]:\n",
    "        fft_result = np.fft.fft(channel_data)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "        frequencies = np.fft.fftfreq(len(fft_result), 1 / sr)\n",
    "        target_amplitudes_trial = []\n",
    "        for target_frequency in target_frequencies:\n",
    "        # encontrando o índice da frequência alvo no espectro de frequência\n",
    "            index = np.argmin(np.abs(frequencies - target_frequency))\n",
    "            # amplitude na frequência alvo\n",
    "            amplitude = np.sqrt(psd[index])\n",
    "            target_amplitudes_trial.append(amplitude)\n",
    "        samples.append(target_amplitudes_trial)\n",
    "    target_amplitudes.append(samples)\n",
    "target_amplitudes = np.array(target_amplitudes)\n",
    "target_amplitudes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular o SNR de \"banda estreita\". Pode ser observado pela seguinte equação:\n",
    "\n",
    "$SNR_{banda\\ estreita} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{média das amplitudes nas frequências vizinhas}}\\right)$\n",
    "\n",
    "Já o SNR de banda larga é definido da seguinte forma:\n",
    "\n",
    "$SNR_{banda\\ larga} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{energia total do espectro de amplitude}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def narrow_band_SNR(target_amplitudes, estimated_background_noise):\n",
    "  target_amplitudes_adjusted = np.abs(target_amplitudes - estimated_background_noise)\n",
    "  return 10 * np.log10(target_amplitudes_adjusted / estimated_background_noise)\n",
    "\n",
    "def wide_band_SNR(target_amplitudes, estimated_background_noise):\n",
    "  target_amplitudes_adjusted = np.abs(target_amplitudes - estimated_background_noise)\n",
    "  total_power = np.sum(target_amplitudes_adjusted)\n",
    "  return 10 * np.log10(target_amplitudes_adjusted / total_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cs e gammas são listas com os valores a serem avaliados para os respectivos parâmetros.\n",
    "def selecionar_melhor_svm(Cs, gammas, X_treino : np.ndarray, X_val : np.ndarray, \n",
    "                          y_treino : np.ndarray, y_val : np.ndarray, n_jobs=4):\n",
    "    \n",
    "    def treinar_svm(C, gamma, X_treino, X_val, y_treino, y_val):\n",
    "        svm = SVC(C=C, gamma=gamma)\n",
    "        svm.fit(X_treino, y_treino)\n",
    "        pred = svm.predict(X_val)\n",
    "        return accuracy_score(y_val, pred)\n",
    "    \n",
    "    #gera todas as combinações de parametros C e gamma, de acordo com as listas de valores recebidas por parametro.\n",
    "    #Na prática faz o produto cartesiano entre Cs e gammas.\n",
    "    combinacoes_parametros = list(itertools.product(Cs, gammas))\n",
    "    \n",
    "    #Treinar modelos com todas as combinações de C e gamma\n",
    "    acuracias_val = Parallel(n_jobs=n_jobs)(delayed(treinar_svm)\n",
    "                                       (c, g, X_treino, X_val, y_treino, y_val) for c, g in combinacoes_parametros)       \n",
    "    \n",
    "    melhor_val = max(acuracias_val)\n",
    "    #Encontrar a combinação que levou ao melhor resultado no conjunto de validação\n",
    "    melhor_comb = combinacoes_parametros[np.argmax(acuracias_val)]   \n",
    "    melhor_c = melhor_comb[0]\n",
    "    melhor_gamma = melhor_comb[1]\n",
    "    \n",
    "    #Treinar uma SVM com todos os dados de treino e validação usando a melhor combinação de C e gamma.\n",
    "    svm = SVC(C=melhor_c, gamma=melhor_gamma)\n",
    "    svm.fit(np.vstack((X_treino, X_val)), [*y_treino, *y_val])\n",
    "\n",
    "    return svm, melhor_comb, melhor_val\n",
    "\n",
    "#Implementa a validação cruzada para avaliar o desempenho da SVM na base de dados com as instâncias X e as saídas y.\n",
    "#cv_splits indica o número de partições que devem ser criadas.\n",
    "#Cs é a lista com os valores C que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "#gammas s é a lista com os valores gamma que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "def do_cv_svm(X, y, cv_splits, Cs=[1], gammas=['scale']):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    acuracias = []\n",
    "    \n",
    "    #pgb = tqdm(total=cv_splits, desc='Folds avaliados')\n",
    "    \n",
    "    for treino_idx, teste_idx in skf.split(X, y):\n",
    "\n",
    "        X_treino = X[treino_idx]\n",
    "        y_treino = y[treino_idx]\n",
    "\n",
    "        X_teste = X[teste_idx]\n",
    "        y_teste = y[teste_idx]\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, test_size=0.2, random_state=42)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_treino)\n",
    "        X_treino = ss.transform(X_treino)\n",
    "        X_teste = ss.transform(X_teste)\n",
    "        X_val = ss.transform(X_val)\n",
    "\n",
    "        svm, _, _ = selecionar_melhor_svm(Cs, gammas, X_treino, X_val, y_treino, y_val)\n",
    "        pred = svm.predict(X_teste)\n",
    "\n",
    "        acuracias.append(accuracy_score(y_teste, pred))\n",
    "        \n",
    "        #pgb.update(1)\n",
    "        \n",
    "    #pgb.close()\n",
    "    \n",
    "    return acuracias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remoção manual de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 80)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = labels\n",
    "\n",
    "for i, trial in enumerate(dataset):\n",
    "  X.append([\n",
    "    narrow_band_SNR(target_amplitudes[i], background_noise[i]),\n",
    "    wide_band_SNR(target_amplitudes[i], background_noise[i])\n",
    "  ])\n",
    "  \n",
    "X = np.array(X)\n",
    "X = X.swapaxes(1, 2)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2]*X.shape[3])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.0625\n",
      "f1_score 0.05208333333333333\n"
     ]
    }
   ],
   "source": [
    "# Remoção\n",
    "# opções: ['PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'POZ', 'O1', 'OZ', 'O2'] -> [47, 53, 54, 55, 56, 57, 60, 61, 62]\n",
    "Xmanual = deepcopy(X)\n",
    "Xmanual = Xmanual[:,[47, 53, 54, 55, 56, 57, 60, 61, 62],:]\n",
    "Xmanual = Xmanual.reshape(Xmanual.shape[0], Xmanual.shape[1]*Xmanual.shape[2])\n",
    "\n",
    "#preparing\n",
    "Xmanual = StandardScaler().fit_transform(Xmanual)\n",
    "ym = LabelEncoder().fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xmanual, ym, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmanual = deepcopy(X)\n",
    "Xmanual = Xmanual[:,[47, 53, 54, 55, 56, 57, 60, 61, 62],:]\n",
    "Xmanual = Xmanual.reshape(Xmanual.shape[0], Xmanual.shape[1]*Xmanual.shape[2])\n",
    "\n",
    "#preparing\n",
    "Xm = StandardScaler().fit_transform(Xmanual)\n",
    "ym = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_svm = do_cv_svm(Xm, ym, 3, Cs=[1, 10, 100, 1000], gammas=['scale', 'auto', 2e-2, 2e-3, 2e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.02, max: 0.04, avg +- std: 0.03 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"min: %.2f, max: %.2f, avg +- std: %.2f +- %.2f\" % (min(accs_svm), max(accs_svm), np.mean(accs_svm), np.std(accs_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remoção automática de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 80)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = labels\n",
    "\n",
    "for i, trial in enumerate(dataset):\n",
    "  X.append([\n",
    "    narrow_band_SNR(target_amplitudes[i], background_noise[i]),\n",
    "    wide_band_SNR(target_amplitudes[i], background_noise[i])\n",
    "  ])\n",
    "  \n",
    "X = np.array(X)\n",
    "X = X.swapaxes(1, 2)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2]*X.shape[3])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing\n",
    "Xauto = deepcopy(X)\n",
    "Xauto = Xauto.reshape(Xauto.shape[0], Xauto.shape[1]*Xauto.shape[2])\n",
    "Xauto = StandardScaler().fit_transform(Xauto)\n",
    "ya = LabelEncoder().fit_transform(y)\n",
    "print(Xauto.shape, ya.shape)\n",
    "\n",
    "#rfe\n",
    "rfe = RFECV(svm.SVC(kernel=\"linear\"), step=0.0001, min_features_to_select=1, cv=3)\n",
    "X_final = rfe.fit_transform(Xauto, ya)\n",
    "print(X_final.shape)\n",
    "\n",
    "#svm\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, ya, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando o Kbest para seleção de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 5120) (160,)\n",
      "accuracy 0.125\n",
      "f1_score 0.13541666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "Xauto = deepcopy(X)\n",
    "Xauto = Xauto.reshape(Xauto.shape[0], Xauto.shape[1]*Xauto.shape[2])\n",
    "Xauto = StandardScaler().fit_transform(Xauto)\n",
    "ya = LabelEncoder().fit_transform(y)\n",
    "print(Xauto.shape, ya.shape)\n",
    "\n",
    "kbest = SelectKBest(f_classif, k=130)\n",
    "X_final = kbest.fit_transform(Xauto, ya)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, ya, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1000, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao final desta etapa, será obtido um vetor de características. Estas podem ser:\n",
    "- `narrow SNR` (brigatória);\n",
    "- `wide-band SNR` (brigatória);\n",
    "- Maior valor espectral (FFT);\n",
    "- Média dos valores espectrais (FFT).\n",
    "\n",
    "Dimensionalidade dos dados será explicada da seguinte forma:\n",
    "\n",
    "`40, 4, 64, 750` -> 40 targets, 4 trials, 64 canais e 750 valores\n",
    "`160, 64 (SNR) + 64 (média) + 64 (maior) ...`\n",
    "Resultando em `160, 192`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de características e classificação\n",
    "\n",
    "Como existem diversos eletrodos (canais) que não obtém sinal SSVEP, podemos extrair as caracteríscas que não contribuem para a classificação dos dados.\n",
    "\n",
    "Podemos utilizar o método `RFE` (*Recursive Feature Elimination*) aplicado por meio de `sklearn.feature_selection.RFE`, aprimorando o parâmetro `n_features_to_select` até obter o melhor resultado de classificação.\n",
    "\n",
    "Para a classificação propriamente dita, é considerado o uso do método `SVM`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
